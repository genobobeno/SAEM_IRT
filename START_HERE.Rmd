---
title: "SAEM_IRT Tutorial"
output: html_notebook
---


# Probit Link MIRT: A Gibbs Sampler Applying SAEM
Welcome to the tutorial on using the SAEM_IRT code to fit your IRT exploratory models.

The first thing we want to do is to appropriately set up your environment for running our code. The following code will appropriately set the working directory and demonstrate the R Notebook features if you have not yet been introduced to this markdown format.
```{r}
knitr::opts_chunk$set(echo=FALSE,warning = FALSE)
source("Hello.R", chdir = T)
Hello()
```

## R Environment and Packages
Before we get started, we'll have to make sure you have some packages installed. We used a C++ implementation for some functions so Rcpp is key. Also, for our parallelization pleasure, we'll include some logic to decide which packages are appropriate in your environment.
```{r,message=FALSE}
### Packages called ###
PACK = c(ifelse(get_os()=="windows","snow","parallel"),"foreach",
         ifelse(get_os()=="windows","doSNOW","doParallel"),
         "rlecuyer","GPArotation","mvnfast","psych","modeest","MASS",
         "Rcpp","RcppArmadillo","devtools","compiler","doRNG","abind",
         "truncdist","truncnorm","modeest","combinat","fastGHQuad","bdsmatrix")

### Install packages not already installed ###
for (i in 1:length(PACK)){
  if(PACK[i] %in% rownames(installed.packages()) == FALSE) {
    install.packages(PACK[i],dependencies = TRUE)}
}
```

Now we source those packages, source our beta functions (pre-CRAN-package) code, and then run some specific code to source the nuanced functions, C++, etc.
```{r, message=FALSE}
required<-lapply(PACK, require, character.only = TRUE)                       # Call the libraries (will deprecate)
Rcpp::sourceCpp("MVNormRand.cpp")                                  # C++ MV Norm Random (fast)
file.sources = list.files(path = "./GeisCamilli/R/",pattern="*.R") # Grab the R functions!
sourced<-sapply(paste0("./GeisCamilli/R/",file.sources),source,.GlobalEnv)  # Source them!
# NOTE: You will not see output when message=FALSE. You will still see warnings, etc.
```


### Assumptions
In running the SAEM algorithm, you'll want to either load your own data or generate data. It is a good idea to generate some data to get a feel for the inputs and outputs, and that's what we'll do here. Several data sets are included to help facilitate your work with this code as well.

Please NOTE the following assumptions here: 

* This suite of functionality assumes orthogonal latent factors in its factor analysis.
* Rotations on output are made based on assumptions about the structure of multidimensionality in items.
* The model uses a probit link. Later in this tutorial, we will transform back to a 2PL or 3PL for pedagogical purposes.
  
## Generate Data
A very simple approach is to generate a small dichotomous test. Let's say 10 items, 500 examinees, and let's keep it simple with a single slope and intercept per item. The latent factor will be a normal distribution, there will be no guessing, and the model of the item characteristic curve will be a probit. There are many other parameters required for properly sampling
```{r}
J = 10; N <- 500; Q <- 1; K <-NA
structure=list(icc="ogive",          # Item Char Curve; "ogive" or "logistic" 
               Adist="beta",         # prior distribution of A's/loadings
               Aparams=c(0.2,1.7),   # parameters of A's/loadings' prior distribution
               Adim=Q,               # 1 (univariate) or 2, 3, etc. multiple dimensions for multivariate
               bdist="norm",         # distribution of B/intercept
               bparams=c(0,1),       # parameters of bdist
               guess=FALSE,          # guessing ? TRUE/FALSE
               ncat=K,               # Ordinal Polythomous? Number of categories
               taudist="norm",       # sample distribution for categorical intercepts
               tauparams=c(0,1),     # parameters for taudist
               cdist="unif",         # guessing parameter distribution for 3PNO or 3PL
               cparams=c(0.05,0.3),  # bounds
               tmu=rep(0,Q),         # Theta Prior... e.g. 0, or multivariate c(0,0) ... can be multidimensional
               tsigma=if(Q==1) 1 else diag(Q), # Latent factor orthogonal covariance
               simfile=paste0("Poly_J",J,"_N",N,"_Q",Q,ifelse(!is.na(K) & K>2,paste0("_K",K),""),".rda"))  # Name of saved file of generated data.
structure = CheckParams(parameters = structure,generate = TRUE) # Explained in a hot minute.
# This will show you the parameters you're using for sampling the response pattern.
VisualizeParams(structure)
```

Now let's generate some response pattern data!
```{r}
Gen.Data<-GenerateTestData(j=J,n=N,structure=structure)
OgiveICC(xi = Gen.Data$XI,guess=structure$guess,j=1)
cat("\nParameters (A and b)\n")
print(head(Gen.Data$XI,n=10))
cat("\nParameters (Theta)\n")
print(head(Gen.Data$THETA))
for (i in 2:5) OgiveICC(xi = Gen.Data$XI,guess=structure$guess,j=i,overlay=TRUE,col=i)
cat("\nResponse Data\n")
print(head(Gen.Data$RP))
```

## Fit Settings 

Now for the complicated part, parameters for fitting the model! 

### Minimal Fix...

If you'd prefer to not think about this, let's start by making a minimal set of features... in fact, we've set this up so you should only need to choose the dimensions. We've got the rest set up for you.

In the block below, we are designating Q = 1. The rest of the settings are a small introduction to the basics of the code's flexibility and are initialized as follows:

* guess = FALSE; No guessing parameter
* empiricalse=FALSE; Don't resample (from conditional distributions given fitted values) for standard errors after the fit
* est="rm"; Use the Robbins-Munro [RM] algorithm
* estgain=1; Set the gain exponent in the denominator of the RM algorithm to 1
* burnin=1000; Run 1000 Gibbs cycles before using RM
* tmu=0; Set prior mean of latent factor to zero
* tsigma=diag(Q); Set prior variance of latent factor to Unity
* eps=1e-4; Set convergence criterion for all item function parameters to 0.0001
* parallel=parallel::detectCores()>2; If you have more than 2 cores, parallelize the algorithm
* estfile="FitFile_Test"; Save the output into an R-Data file "FitFile_Test.rda"

Note: Since there are more settings than this subset, the CheckParams() function will fill in the blanks with defaults and run a *thin* validation! The same is true for the generate structure parameters (the 'generate' argument is the switch).
```{r}
Q <- 1 # Number of dimensions to fit, chosen above... but here for pedagogy
settings = list(Adim=Q,guess=FALSE,empiricalse=FALSE,est="rm",estgain=1,burnin=1000,
                tmu=rep(0,Q),tsigma=diag(Q),eps=1e-4,parallel=(parallel::detectCores()>2),                             estfile="FitFile_Test")
settings<-CheckParams(parameters = settings,generate=FALSE)
```

## Fit the Data

Now that we have response data, we want to fit it using our MIRT Gibbs Sampler. 
NOTE: I apologize that I have yet to fully embrace R's object-oriented S4 classes; a great deal of the functions in this project could probably be more efficiently streamlined with those enhancements. 

```{r}
MyFirstFit<-AnalyzeTestData(RP=Gen.Data$RP,settings=settings)
```

Hopefully that went well... and you now have accomplisted your first fit!

Let's see how it did! First, let's start with the slopes:
```{r}
plot(Gen.Data$XI[,1:Q],MyFirstFit$A,xlab="Generated Slopes",ylab="Fitted Slopes",main=paste("Slope Reconstruction; N =",N))
fittest<-lm(MyFirstFit$A~Gen.Data$XI[,1:Q])
abline(fittest)
summary(fittest)
```

We don't expect perfection with only 500 examinees. Intercepts always look better, so let's check them out:
```{r}
plot(Gen.Data$XI[,Q+1],MyFirstFit$B,xlab="Generated Intercepts",ylab="Fitted Intercepts",main=paste("Difficulty Reconstruction; N =",N),col=1:J,pch=16)
fittest<-lm(MyFirstFit$B~Gen.Data$XI[,Q+1])
abline(fittest)
summary(fittest)
```

As long as you have taken the default for the "extended" parameters that were not explicitly declared, you have the opportunity to visualize the Markov chain! The iteration of these values are saved in another file that should have found its way into your current working directory.

```{r}
load("FitFile_Test.rda") # This will create an object called MCMCDATA and another called FitDATA
cat("Dimensions of the MCMC Matrix of slopes is [J X Q X Iteration]: ",dim(MCMCDATA$Aiter)) # This matrix
plot(c(1,dim(MCMCDATA$Aiter)[3]),range(MCMCDATA$Aiter[,1,]),type="n",main=paste("The",J,"Slopes' Markov Chains"),
     ylab="Slope",xlab="Gibbs cycle")
for (j in 1:J) lines(1:dim(MCMCDATA$Aiter)[3],MCMCDATA$Aiter[j,1,],col=j)
```

And one more time for the Intercepts:

```{r}
cat("Dimensions of the MCMC Matrix of intercepts is [J X Iteration]: ",dim(MCMCDATA$Biter)) # This matrix
plot(c(1,dim(MCMCDATA$Biter)[2]),range(MCMCDATA$Biter),type="n",main=paste("The",J,"Intercepts' Markov Chains"),
     ylab="Intercept",xlab="Gibbs cycle")
for (j in 1:J) lines(1:dim(MCMCDATA$Biter)[2],MCMCDATA$Biter[j,],col=j)
```
